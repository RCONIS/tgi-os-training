---
title: "1. Calculate Bayesian Predictive Power"
author:
  - Daniel Sabanés Bové
  - Francois Mercier
date: last-modified
editor_options: 
  chunk_output_type: inline
format:
  html:
    code-fold: show
    html-math-method: mathjax
cache: true
---

The purpose of this document is to show how we can calculate the probability of success given interim data of a clinical trial, based on the TGI-OS joint model results.

## Setup and load data

Here we execute the R code from the setup and data preparation chapter, see the [full code here](0_setup.qmd).

```{r}
#| label: setup_and_load_data
#| echo: false
#| output: false
library(here)
options(knitr.duplicate.label = "allow")

knitr::purl(
    here("session-bpp/_setup.qmd"),
    output = here("session-bpp/_setup.R")
)
source(here("session-jm/_setup.R"))

knitr::purl(
    here("session-bpp/_load_data.qmd"),
    output = here("session-bpp/_load_data.R")
)
source(here("session-bpp/_load_data.R"))
```

## Fit our joint TGI-OS model

Let's fit again the same joint TGI-OS model as in the previous session. Now we just put all the code together in a single chunk, and it is a good repetition to see all the steps in one place:

```{r}
#| label: fit_joint_model

subj_df <- os_data |>
    mutate(study = "OAK") |>
    select(study, id, arm)
subj_data <- DataSubject(
    data = subj_df,
    subject = "id",
    arm = "arm",
    study = "study"
)
long_df <- tumor_data |>
    select(id, year, sld)
long_data <- DataLongitudinal(
    data = long_df,
    formula = sld ~ year
)
surv_data <- DataSurvival(
    data = os_data,
    formula = Surv(os_time, os_event) ~ ecog + age + race + sex
)
joint_data <- DataJoint(
    subject = subj_data,
    longitudinal = long_data,
    survival = surv_data
)

joint_mod <- JointModel(
    longitudinal = LongitudinalSteinFojo(
        mu_bsld = prior_normal(log(65), 1),
        mu_ks = prior_normal(log(0.52), 1),
        mu_kg = prior_normal(log(1.04), 1),
        omega_bsld = prior_normal(0, 3) |> set_limits(0, Inf),
        omega_ks = prior_normal(0, 3) |> set_limits(0, Inf),
        omega_kg = prior_normal(0, 3) |> set_limits(0, Inf),
        sigma = prior_normal(0, 3) |> set_limits(0, Inf)
    ),
    survival = SurvivalWeibullPH(
        lambda = prior_gamma(0.7, 1),
        gamma = prior_gamma(1.5, 1),
        beta = prior_normal(0, 20)
    ),
    link = linkGrowth(
        prior = prior_normal(0, 20)
    )
)

options("jmpost.prior_shrinkage" = 0.99)
initialValues(joint_mod, n_chains = CHAINS)

save_file <- here("session-bpp/jm1.rds")
if (file.exists(save_file)) {
    joint_results <- readRDS(save_file)
} else {
    joint_results <- sampleStanModel(
        joint_mod,
        data = joint_data,
        iter_sampling = ITER,
        iter_warmup = WARMUP,
        chains = CHAINS,
        parallel_chains = CHAINS,
        thin = CHAINS,
        seed = BAYES.SEED,
        refresh = REFRESH
    )
    saveObject(joint_results, file = save_file)
}
```

## Marginal Hazard Ratio Estimation

First, we will try to apply the methodology from [Oudenhoven et al (2020)](https://onlinelibrary.wiley.com/doi/10.1002/sim.8713) to estimate the marginal hazard ratio, using our joint model results.
We use the new `jmpost` function called `populationHR()` for this:

```{r}
pop_hr <- populationHR(
    joint_results,
    hr_formula = ~arm
)
pop_hr$summary
```

So here we have the marginal log hazard ratio estimates of the baseline spline components and the treatment arm.
Therefore we can get the hazard ratio estimates by exponentiating the log hazard ratio estimates:

```{r}
hr_est <- pop_hr$summary["armMPDL3280A", ] |>
    sapply(exp)
```

So we get a marginal hazard ratio estimate of around `r round(hr_est["mean"], 3)` and a 95% credible interval of `r paste0(signif(hr_est[c("X2.5.", "X97.5.")], 2), collapse = " - ")`. 

## Comparison with simple Cox PH results

We can do a little sanity check by comparing this with a very simple Cox model:

```{r}
cox_mod <- survival::coxph(
    update(joint_results@data@survival@formula, ~ . + arm),
    data = joint_results@data@survival@data
)
summary(cox_mod)
```

Here we get a different HR estimate of around `r round(exp(coef(cox_mod)["armMPDL3280A"]), 2)`, which is lower than the one we got from the joint model. 
We should expect different results because the joint model takes into account the TGI effect, while the Cox model does not.

And if we just put the treatment arm into the Cox model we get:

```{r}
cox_mod_arm <- survival::coxph(
    update(joint_results@data@survival@formula, . ~ arm),
    data = joint_results@data@survival@data
)
cox_mod_arm
```

Here we get a HR of `r round(exp(coef(cox_mod_arm)["armMPDL3280A"]), 3)` that is close to the marginal HR estimate above (when we did not condition on the other covariates), which is reassuring.
On the other hand, the 95% confidence interval is:

```{r}
exp(confint(cox_mod_arm)["armMPDL3280A", ])
```

so actually overlaps the null hypothesis of 1. So we see that the joint model helped us to obtain a more precise estimate of the marginal hazard ratio.




## Individual Samples based Predictive Power

- Sample events for the patients who did not have an event yet
  - based on their conditional survival distribution estimated by the TGI-OS model
- Determine the cutoff time based on the total number of events
- Plug this data set into e.g. log rank test and get test statistic
- Doing this over all the samples, we get a distribution of the test statistic
  - Maybe even do this 10 times for each sample because we have some uncertainty there too
- Then can just look at the proportion of test statistic samples which are above our critical value and then this is our predictive power  